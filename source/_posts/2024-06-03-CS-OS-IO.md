---
title: 操作系统之网络编程心得
date: 2024-06-03 19:00:47
categories: 操作系统
tags: [操作系统, 网络编程]
description: 
---

操作系统中最慢的部分就是IO：
网络 毫秒级~秒级，HDD 毫秒级，SSD 微秒级，内存 纳秒级

## 零拷贝 和 异步IO

### 文件传输 内存拷贝 上下文切换

一次数据传输，可能涉及多次内存拷贝，内核与用户态间的拷贝带来系统调用，系统调用需要两次上下文切换。

* 首先，`上下文切换`需要 几十纳秒 ~ 几微秒，高并发环境容易被累积放大

* 其次，`内存拷贝`也会消耗CPU资源，CPU搬运数据是利用寄存器一次一个字节地搬

### DMA

DMA帮CPU省去在IO设备缓冲区和内核缓冲区之间的数据搬运，但CPU还是要在内核缓冲区和用户缓冲区之间搬运。

一次发送文件，经历 read和write 两次系统调用，四次内存拷贝（磁盘缓冲区-PageCache-用户态缓冲区-socket内核缓冲区-网卡缓冲区）。

### 零拷贝

所谓的`零拷贝技术`，就是没有在内存层面去拷贝数据，全程没有通过CPU来搬运数据，所有的数据都是通过DMA来进行传输。

#### mmap + write

mmap系统调用函数把内核缓冲区里的数据`映射`到用户空间。

省去在内核缓冲区和用户缓冲区之间搬运数据，变成三次内存拷贝，但 mmap和write 还是要两次系统调用。

#### sendfile

在Linux内核版本2.1中，提供了一个专门发送文件的系统调用函数sendfile，指定源fd和目的fd,实现一次系统调用，三次内存拷贝。

#### SG-DMA

如果网卡支持 The Scatter-Gather Direct Memory Access 技术，就可以让sendfile系统调用只进行两次内存拷贝。只需要给socket缓冲区传fd和数据长度，就可以直接从PageCache拷贝到网卡缓冲区。

### PageCache

利用`局部性原理`，缓存最近访问的磁盘数据，按`lru`淘汰。

内核优化：

* 内核IO调度算法会缓存尽可能多请求在PageCache中，最后`合并`成一个更大的IO请求再发给磁盘，减少磁盘的寻址操作

* 利用`预读`功能，从顺序读的性能优势中获益。

但是不适合传输GB级别大文件，（1）不适用局部性，浪费DMA从磁盘缓冲区到PageCache的拷贝，（2）PageCache长时间被大文件占据，热点小文件无法利用PageCache

### 缓存IO 直接IO

缓存IO利用PageCache；直接IO，绕开了PageCache，DMA直接将数据从磁盘缓冲区搬运到用户缓冲区。

直接IO场景，（1）传输大文件，（2）应用程序自己实现了磁盘数据缓存，想绕开PageCache提高性能。

直接IO失去PageCache的合并和预读的优势。

### 异步IO

异步IO发起系统调用后，不用等待数据就位直接返回；磁盘缓冲区搬运到用户缓冲区后，进程收到内核通知再处理数据。

在高并发的场景下，针对大文件的传输的方式，应该使用`异步IO+直接IO`来替代零拷贝技术。

## 
